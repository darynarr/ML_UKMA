{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMDB Review Classification Battlefield - Contestants : Feedforward, CNN, RNN, LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we are going to do sentiment classification on a movie review dataset. We are going to build a feedforward net, a convolutional neural net, a recurrent net and combine one or more of them to understand performance of each of them. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. There are also semantic connections backwards in a sentence, in an ideal case (in which we use RNNs from both directions and combine their outputs). But for the purpose of this tutorial, we are going to restrict ourselves to only uni-directional RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small\n",
    "vocabulary_size = 10000\n",
    "\n",
    "#We also want to have a finite length of reviews and not have to process really long sentences.\n",
    "max_review_length = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOKENIZATION\n",
    "\n",
    "For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example.\n",
    "\n",
    "Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary.\n",
    "\n",
    "1. i have books - [1, 4, 7]\n",
    "2. interesting books are useful [10,2,9,8]\n",
    "3. i have computers [1,4,6]\n",
    "4. computers are interesting and useful [6,9,11,10,8]\n",
    "5. books and computers are both valuable. [2,10,2,9,13,12]\n",
    "6. Bye Bye [7,7]\n",
    "\n",
    "Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens\n",
    "\n",
    "I-1, books-2, computers-3, have-4, are-5, computers-6,bye-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13\n",
    "\n",
    "Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb \n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/keras/datasets/imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews 25000\n",
      "Length of first and fifth review before padding 218 147\n",
      "First review [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "First label 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/keras/datasets/imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "\n",
    "print('Number of reviews', len(X_train))\n",
    "print('Length of first and fifth review before padding', len(X_train[0]) ,len(X_train[4]))\n",
    "print('First review', X_train[0])\n",
    "print('First label', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n",
    "\n",
    "Pad sequences in order to ensure that all inputs have same sentence length and dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first and fifth review after padding 500 500\n"
     ]
    }
   ],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "print('Length of first and fifth review after padding', len(X_train[0]) ,len(X_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE.type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS \n",
    "\n",
    "Let us build a single layer feedforward net with 250 nodes. Each input would be a 500-dim vector of tokens since we padded all our sequences to size 500.\n",
    "\n",
    "<b> EXERCISE </b> : Calculate the number of parameters involved in this network and implement a feedforward net to do classification without looking at cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = X_train.shape[1]\n",
    "H = 250\n",
    "D_out = 1\n",
    "\n",
    "# X, y = torch.from_numpy(X_train).to(DEVICE), torch.from_numpy(y_train).float().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "verbose = 1\n",
    "learning_rate = 1e-2\n",
    "batch_size=64\n",
    "optimizer = torch.optim.Adam\n",
    "criteria = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(inputs, labels, model, criteria, optimizer):\n",
    "    model.train()\n",
    "    permutation = torch.randperm(inputs.size()[0])\n",
    "    losses, accs = [], []\n",
    "        \n",
    "    for i in range(0,inputs.size()[0], batch_size):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = inputs[indices], labels[indices]\n",
    "\n",
    "        output = model(batch_x)[:,0]\n",
    "        optimizer.zero_grad()\n",
    "        loss = criteria(output, batch_y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = output > 0.5\n",
    "        correct = (preds == batch_y).sum()\n",
    "        acc = correct / float(batch_y.shape[0])\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc.item())\n",
    "    losses, accs = np.array(losses), np.array(accs)\n",
    "    return np.mean(losses), np.mean(accs)\n",
    "\n",
    "def eval_epoch(inputs, labels, model, criteria):\n",
    "    model.eval()\n",
    "    ids = [i for i in range(inputs.size()[0])]\n",
    "    losses, accs = [], []\n",
    "    for i in range(0,inputs.size()[0], batch_size):\n",
    "\n",
    "        indices = ids[i:i+batch_size]\n",
    "        batch_x, batch_y = inputs[indices], labels[indices]\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            output = model(batch_x)[:,0]\n",
    "            loss = criteria(output, batch_y.float())\n",
    "\n",
    "            preds = output > 0.5\n",
    "            correct = (preds == batch_y).sum()\n",
    "            acc = correct / float(batch_y.shape[0])\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc.item())\n",
    "        \n",
    "    losses, accs = np.array(losses), np.array(accs)\n",
    "    return np.mean(losses), np.mean(accs)\n",
    "    \n",
    "    \n",
    "def train(X, y, X_val, y_val,\n",
    "          model, epochs, verbose, learning_rate, criteria, optimizer, batch_size=64):\n",
    "    \n",
    "    inputs, labels = torch.from_numpy(X).to(DEVICE), torch.from_numpy(y).to(DEVICE)\n",
    "    inputs_val, labels_val = torch.from_numpy(X_val).to(DEVICE), torch.from_numpy(y_val).to(DEVICE)\n",
    "    \n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    log_template = \"\\n[{ep:03d}/{epochs:03d}] train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = fit_epoch(inputs, labels, model, criteria, optimizer)\n",
    "        val_loss, val_acc = eval_epoch(inputs_val, labels_val, model, criteria)\n",
    "        \n",
    "        history.append([train_loss, train_acc, val_loss, val_acc])\n",
    "        if (epoch==0) or (epoch%verbose==0) or (epoch==epochs-1):\n",
    "            print(log_template.format(ep=epoch+1, epochs=epochs, t_loss=train_loss,\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(D_in, H)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_.float())\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = SimpleNet().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/015] train_loss: 13.9541     val_loss 13.8124 train_acc 0.4960 val_acc 0.5001\n",
      "\n",
      "[002/015] train_loss: 13.8169     val_loss 13.8244 train_acc 0.5000 val_acc 0.4999\n",
      "\n",
      "[003/015] train_loss: 13.8123     val_loss 13.8175 train_acc 0.5001 val_acc 0.5000\n",
      "\n",
      "[004/015] train_loss: 13.8131     val_loss 13.8175 train_acc 0.5001 val_acc 0.5000\n",
      "\n",
      "[005/015] train_loss: 13.8151     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[006/015] train_loss: 13.8171     val_loss 13.8175 train_acc 0.4999 val_acc 0.5000\n",
      "\n",
      "[007/015] train_loss: 13.8151     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[008/015] train_loss: 13.8157     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[009/015] train_loss: 13.8164     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[010/015] train_loss: 13.8144     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[011/015] train_loss: 13.8144     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[012/015] train_loss: 13.8137     val_loss 13.8175 train_acc 0.5001 val_acc 0.5000\n",
      "\n",
      "[013/015] train_loss: 13.8190     val_loss 13.8175 train_acc 0.4999 val_acc 0.5000\n",
      "\n",
      "[014/015] train_loss: 13.8157     val_loss 13.8175 train_acc 0.5000 val_acc 0.5000\n",
      "\n",
      "[015/015] train_loss: 13.8137     val_loss 13.8175 train_acc 0.5001 val_acc 0.5000\n"
     ]
    }
   ],
   "source": [
    "simple_history = train(X_train, y_train, X_test, y_test, simple_model, \n",
    "      epochs=15, verbose=1, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion : Why was the performance bad ? What was wrong with tokenization ? \n",
    "\n",
    "### MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS\n",
    "\n",
    "#### What is an embedding layer ? \n",
    "\n",
    "An embedding is a linear projection from one vector space to another. We usually use embeddings to project the one-hot encodings of words on to a lower-dimensional continuous space so that the input surface is dense and possibly smooth. According to the model, an embedding layer is just a transformation from $\\mathbb{R}^{inp}$ to $\\mathbb{R}^{emb}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do embedding to dim 100 (in keras, tf, PyTorch: with Embedding layer) and after flattening add a dense layer with 250 units. Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_emb = 100\n",
    "class EmbeddingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocabulary_size, H_emb)\n",
    "        self.dp1 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(H_emb * D_in, H)\n",
    "        self.dp2 = torch.nn.Dropout(0.5)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        emb = self.emb(input_.long()).view((input_.size(0), -1))\n",
    "        dp1 = self.dp1(emb)\n",
    "        a1 = self.fc1(dp1)\n",
    "        dp2 = self.dp2(a1)\n",
    "        a2 = self.out(dp2)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/050] train_loss: 7.4095     val_loss 0.8028 train_acc 0.5088 val_acc 0.5114\n",
      "\n",
      "[006/050] train_loss: 0.3679     val_loss 0.4482 train_acc 0.8364 val_acc 0.7992\n",
      "\n",
      "[011/050] train_loss: 0.2108     val_loss 0.4478 train_acc 0.9165 val_acc 0.8354\n",
      "\n",
      "[016/050] train_loss: 0.1500     val_loss 0.6077 train_acc 0.9457 val_acc 0.8419\n",
      "\n",
      "[021/050] train_loss: 0.1260     val_loss 0.6249 train_acc 0.9592 val_acc 0.8430\n",
      "\n",
      "[026/050] train_loss: 0.1059     val_loss 0.8599 train_acc 0.9688 val_acc 0.8516\n",
      "\n",
      "[031/050] train_loss: 0.0935     val_loss 1.1010 train_acc 0.9743 val_acc 0.8517\n",
      "\n",
      "[036/050] train_loss: 0.0971     val_loss 1.1076 train_acc 0.9771 val_acc 0.8550\n",
      "\n",
      "[041/050] train_loss: 0.0828     val_loss 1.5285 train_acc 0.9829 val_acc 0.8564\n",
      "\n",
      "[046/050] train_loss: 0.0667     val_loss 1.6448 train_acc 0.9870 val_acc 0.8596\n",
      "\n",
      "[050/050] train_loss: 0.1006     val_loss 1.9589 train_acc 0.9846 val_acc 0.8570\n"
     ]
    }
   ],
   "source": [
    "emb_model = EmbeddingNet().to(DEVICE)\n",
    "emb_history = train(X_train, y_train, X_test, y_test, emb_model, \n",
    "      epochs=50, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2 : CONVOLUTIONAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog.\n",
    "\n",
    "http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/\n",
    "\n",
    "Fit a 1D convolution with 200 filters, kernel size 3 followed by a feedforward layer of 250 nodes and ReLU, sigmoid activations as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_conv = 200\n",
    "H=250\n",
    "C_in = 1\n",
    "k_size = 3\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 =nn.Conv1d(C_in, H_conv, kernel_size=k_size, padding=1)\n",
    "#         self.p1 = nn.AvgPool1d(H_conv)\n",
    "        self.fc1 = nn.Linear(H_conv*D_in, H)\n",
    "        self.fc2 = nn.Linear(H, D_out)\n",
    "        self.out = nn.ReLU()\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        conv = self.c1(input_.float().view(input_.size(0), 1, input_.size(1))) # (N, C_in, L)\n",
    "        a1 = self.fc1(conv.view(input_.size(0), -1))\n",
    "        a2 = self.fc2(a1)\n",
    "        a3 = self.out(a2)\n",
    "        y = self.out_act(a3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/015] train_loss: 0.7083     val_loss 0.6931 train_acc 0.4999 val_acc 0.4999\n",
      "\n",
      "[006/015] train_loss: 0.6931     val_loss 0.6931 train_acc 0.5001 val_acc 0.4999\n",
      "\n",
      "[011/015] train_loss: 0.6931     val_loss 0.6931 train_acc 0.4999 val_acc 0.4999\n",
      "\n",
      "[015/015] train_loss: 0.6931     val_loss 0.6931 train_acc 0.5001 val_acc 0.4999\n"
     ]
    }
   ],
   "source": [
    "conv_model = ConvNet().to(DEVICE)\n",
    "conv_history = train(X_train, y_train, X_test, y_test, conv_model, \n",
    "      epochs=15, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3 : SIMPLE RNN\n",
    "\n",
    "Two of the best blogs that help understand the workings of a RNN and LSTM are\n",
    "\n",
    "1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "2. http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "Mathematically speaking, a simple RNN does the following. It constructs a set of hidden states using the state variable from the previous timestep and the input at current time. Mathematically, a simpleRNN can be defined by the following relation.\n",
    "\n",
    "<center>$h_t = \\sigma(W([h_{t-1},x_{t}])+b)$\n",
    "    \n",
    "If we extend this recurrence relation to the length of sequences we have in hand, we have our RNN network constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do simple RNN (keras, rf: SimpleRNN layer, pytorch: RNN layer) with 100 units with the input from embedding layer. How are the results different from the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_emb = 100\n",
    "class RNNNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocabulary_size, H_emb)\n",
    "        self.rnn = nn.RNN(H_emb, H)\n",
    "        self.dp1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(D_in * H, H)\n",
    "        self.dp2 = nn.Dropout(0.5)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        emb = self.emb(input_.long())\n",
    "        rnn, hid = self.rnn(emb)\n",
    "        rnn = self.dp1(rnn)\n",
    "        a1 = self.fc1(rnn.view((input_.size(0), -1)))\n",
    "        a1 = self.dp2(a1)\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/020] train_loss: 0.7962     val_loss 0.6883 train_acc 0.5377 val_acc 0.5865\n",
      "\n",
      "[006/020] train_loss: 0.3621     val_loss 0.6388 train_acc 0.8364 val_acc 0.6993\n",
      "\n",
      "[011/020] train_loss: 0.2443     val_loss 0.6584 train_acc 0.8953 val_acc 0.7383\n",
      "\n",
      "[016/020] train_loss: 0.1821     val_loss 0.7017 train_acc 0.9236 val_acc 0.7557\n",
      "\n",
      "[020/020] train_loss: 0.1467     val_loss 0.7315 train_acc 0.9400 val_acc 0.7673\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNNet().to(DEVICE)\n",
    "rnn_history = train(X_train, y_train, X_test, y_test, rnn_model,\n",
    "      epochs=20, verbose=5, learning_rate=1e-4, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNNs and vanishing/exploding gradients\n",
    "\n",
    "Let us use sigmoid activations as example. Derivative of a sigmoid can be written as \n",
    "<center> $\\sigma'(x) = \\sigma(x) \\cdot \\sigma(1-x)$. </center>\n",
    "\n",
    "<img src = \"fig/vanishing_gradients.png\">\n",
    "Remember RNN is a \"really deep\" feedforward network (when unrolled in time). Hence, backpropagation happens from $h_t$ all the way to $h_1$. Also realize that sigmoid gradients are multiplicatively dependent on the value of sigmoid. Hence, if the non-activated output of any layer $h_l$ is < 0, then $\\sigma$ tends to 0, effectively \"vanishing\" gradient. Any layer that the current layer backprops to $H_{1:L-1}$ do not learn anything useful out of the gradients.\n",
    "\n",
    "#### LSTMs and GRU\n",
    "LSTM and GRU are two sophisticated implementations of RNN which essentially are built on what we call as gates. A gate is a probability number between 0 and 1. For instance, LSTM is built on these state updates \n",
    "\n",
    "Note : L is just a linear transformation L(x) = W*x + b.\n",
    "\n",
    "$f_t = \\sigma(L([h_{t-1},x_t))$\n",
    "\n",
    "$i_t = \\sigma(L([h_{t-1},x_t))$\n",
    "\n",
    "$o_t = \\sigma(L([h_{t-1},x_t))$\n",
    "\n",
    "$\\hat{C}_t = \\tanh(L([h_{t-1},x_t))$\n",
    "\n",
    "$C_t = f_t * C_{t-1}+i_t*\\hat{C}_t$  (Using the forget gate, the neural network can learn to control how much information it has to retain or forget)\n",
    "\n",
    "$h_t = o_t * \\tanh(c_t)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4 : LSTM\n",
    "\n",
    "In the next step, we will implement a LSTM model to do classification. Use the same architecture as before. Try experimenting with increasing the number of nodes, stacking multiple layers, applyong dropouts etc. Check the number of parameters that this model entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_emb = 100\n",
    "class LSTMNet(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocabulary_size, H_emb)\n",
    "        self.lstm = nn.LSTM(H_emb, H)\n",
    "        self.dp1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(D_in * H, H)\n",
    "        self.dp2 = nn.Dropout(0.5)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        emb = self.emb(input_.long())\n",
    "#         print(emb.size())\n",
    "        lstm, hid = self.lstm(emb)\n",
    "        lstm = self.dp1(lstm)\n",
    "        a1 = self.fc1(lstm.view((input_.size(0), -1)))\n",
    "        a1 = self.dp2(a1)\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/020] train_loss: 0.7023     val_loss 0.6595 train_acc 0.5483 val_acc 0.6061\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-77bd1d4fa8d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m lstm_history = train(X_train, y_train, X_test, y_test, lstm_model,\n\u001b[0;32m----> 3\u001b[0;31m       epochs=20, verbose=5, learning_rate=1e-4, criteria=criteria, optimizer=optimizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-de9bc5ac7d9e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, y, X_val, y_val, model, epochs, verbose, learning_rate, criteria, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-de9bc5ac7d9e>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(inputs, labels, model, criteria, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model = LSTMNet().to(DEVICE)\n",
    "lstm_history = train(X_train, y_train, X_test, y_test, lstm_model,\n",
    "      epochs=20, verbose=5, learning_rate=1e-4, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5 : CNN + LSTM \n",
    "\n",
    "CNNs are good at learning spatial features and sentences can be thought of as 1-D spatial vectors (dimension being connotated by the sequence ordering among the words in the sentence.). We apply a LSTM over the features learned by the CNN (after a maxpooling layer). This leverages the power of CNNs and LSTMs combined. We expect the CNN to be able to pick out invariant features across the 1-D spatial structure(i.e. sentence) that characterize good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer followed by a feedforward for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_conv = 200\n",
    "H=250\n",
    "k_size = 3\n",
    "p_size = 5\n",
    "\n",
    "class ConvLSTMNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv1d(C_in, H_conv, k_size, padding=k_size//2)\n",
    "        self.p1 = nn.MaxPool1d(p_size)\n",
    "        self.lstm = nn.LSTM(D_in, H)\n",
    "        self.fc1 = nn.Linear((H_conv // p_size) * H, D_out)\n",
    "        self.out = nn.ReLU()\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        c1 = self.c1(input_.float().view(input_.size(0), 1, input_.size(1)))\n",
    "        c1 = self.p1(c1.view(input_.size(0), D_in, H_conv))\n",
    "\n",
    "        a1, hid = self.lstm(c1.transpose(1, 2).transpose(0, 1))\n",
    "        a2 = self.fc1(a1.transpose(1,0).reshape((input_.size(0), -1)))\n",
    "    \n",
    "        a3 = self.out(a2)\n",
    "        y = self.out_act(a3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/020] train_loss: 0.6932     val_loss 0.6931 train_acc 0.5000 val_acc 0.4999\n",
      "\n",
      "[006/020] train_loss: 0.6931     val_loss 0.6931 train_acc 0.4999 val_acc 0.4999\n",
      "\n",
      "[011/020] train_loss: 0.6931     val_loss 0.6931 train_acc 0.5000 val_acc 0.4999\n",
      "\n",
      "[016/020] train_loss: 0.6931     val_loss 0.6931 train_acc 0.5000 val_acc 0.4999\n",
      "\n",
      "[020/020] train_loss: 0.6931     val_loss 0.6931 train_acc 0.5001 val_acc 0.4999\n"
     ]
    }
   ],
   "source": [
    "convlstm_model = ConvLSTMNet().to(DEVICE)\n",
    "convlstm_history = train(X_train, y_train, X_test, y_test, convlstm_model,\n",
    "      epochs=20, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "\n",
    "We saw the power of sequence models and how they are useful in text classification. They give a solid performance, low memory footprint (thanks to shared parameters) and are able to understand and leverage the temporally connected information contained in the inputs. There is still an open debate about the performance vs memory benefits of CNNs vs RNNs in the research community."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_ukma]",
   "language": "python",
   "name": "conda-env-ml_ukma-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
