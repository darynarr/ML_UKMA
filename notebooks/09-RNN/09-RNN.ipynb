{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMDB Review Classification Battlefield - Contestants : Feedforward, CNN, RNN, LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we are going to do sentiment classification on a movie review dataset. We are going to build a feedforward net, a convolutional neural net, a recurrent net and combine one or more of them to understand performance of each of them. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. There are also semantic connections backwards in a sentence, in an ideal case (in which we use RNNs from both directions and combine their outputs). But for the purpose of this tutorial, we are going to restrict ourselves to only uni-directional RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small\n",
    "vocabulary_size = 10000\n",
    "\n",
    "#We also want to have a finite length of reviews and not have to process really long sentences.\n",
    "max_review_length = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOKENIZATION\n",
    "\n",
    "For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example.\n",
    "\n",
    "Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary.\n",
    "\n",
    "1. i have books - [1, 4, 7]\n",
    "2. interesting books are useful [10,2,9,8]\n",
    "3. i have computers [1,4,6]\n",
    "4. computers are interesting and useful [6,9,11,10,8]\n",
    "5. books and computers are both valuable. [2,10,2,9,13,12]\n",
    "6. Bye Bye [7,7]\n",
    "\n",
    "Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens\n",
    "\n",
    "I-1, books-2, computers-3, have-4, are-5, computers-6,bye-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13\n",
    "\n",
    "Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daryna/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb \n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/keras/datasets/imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/keras/datasets/imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews 25000\n",
      "Length of first and fifth review before padding 218 147\n",
      "First review [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "First label 1\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "\n",
    "print('Number of reviews', len(X_train))\n",
    "print('Length of first and fifth review before padding', len(X_train[0]) ,len(X_train[4]))\n",
    "print('First review', X_train[0])\n",
    "print('First label', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n",
    "\n",
    "Pad sequences in order to ensure that all inputs have same sentence length and dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first and fifth review after padding 500 500\n"
     ]
    }
   ],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "print('Length of first and fifth review after padding', len(X_train[0]) ,len(X_train[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "print(DEVICE.type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS \n",
    "\n",
    "Let us build a single layer feedforward net with 250 nodes. Each input would be a 500-dim vector of tokens since we padded all our sequences to size 500.\n",
    "\n",
    "<b> EXERCISE </b> : Calculate the number of parameters involved in this network and implement a feedforward net to do classification without looking at cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = X_train.shape[1]\n",
    "H = 250\n",
    "D_out = 1\n",
    "\n",
    "# X, y = torch.from_numpy(X_train).to(DEVICE), torch.from_numpy(y_train).float().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "verbose = 1\n",
    "learning_rate = 1e-2\n",
    "batch_size=64\n",
    "optimizer = torch.optim.SGD\n",
    "criteria = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_epoch(inputs, labels, model, criteria, optimizer):\n",
    "    model.train()\n",
    "    permutation = torch.randperm(inputs.size()[0])\n",
    "    losses, accs = [], []\n",
    "        \n",
    "    for i in range(0,inputs.size()[0], batch_size):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = inputs[indices], labels[indices]\n",
    "\n",
    "        output = model(batch_x)[:,0]\n",
    "        optimizer.zero_grad()\n",
    "        loss = criteria(output, batch_y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = output > 0.5\n",
    "        correct = (preds == batch_y).sum()\n",
    "        acc = correct / float(batch_y.shape[0])\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc.item())\n",
    "    losses, accs = np.array(losses), np.array(accs)\n",
    "    return np.mean(losses), np.mean(accs)\n",
    "\n",
    "def eval_epoch(inputs, labels, model, criteria):\n",
    "    model.eval()\n",
    "    ids = [i for i in range(inputs.size()[0])]\n",
    "    losses, accs = [], []\n",
    "    for i in range(0,inputs.size()[0], batch_size):\n",
    "\n",
    "        indices = ids[i:i+batch_size]\n",
    "        batch_x, batch_y = inputs[indices], labels[indices]\n",
    "        \n",
    "        with torch.set_grad_enabled(False):\n",
    "            output = model(batch_x)[:,0]\n",
    "            loss = criteria(output, batch_y.float())\n",
    "\n",
    "            preds = output > 0.5\n",
    "            correct = (preds == batch_y).sum()\n",
    "            acc = correct / float(batch_y.shape[0])\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accs.append(acc.item())\n",
    "        \n",
    "    losses, accs = np.array(losses), np.array(accs)\n",
    "    return np.mean(losses), np.mean(accs)\n",
    "    \n",
    "    \n",
    "def train(X, y, X_val, y_val,\n",
    "          model, epochs, verbose, learning_rate, criteria, optimizer, batch_size=64):\n",
    "    \n",
    "    inputs, labels = torch.from_numpy(X).to(DEVICE), torch.from_numpy(y).to(DEVICE)\n",
    "    inputs_val, labels_val = torch.from_numpy(X_val).to(DEVICE), torch.from_numpy(y_val).to(DEVICE)\n",
    "    \n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    log_template = \"\\n[{ep:03d}/{epochs:03d}] train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = fit_epoch(inputs, labels, model, criteria, optimizer)\n",
    "        val_loss, val_acc = eval_epoch(inputs_val, labels_val, model, criteria)\n",
    "        \n",
    "        history.append([train_loss, train_acc, val_loss, val_acc])\n",
    "        if (epoch==0) or (epoch%verbose==0) or (epoch==epochs-1):\n",
    "            print(log_template.format(ep=epoch+1, epochs=epochs, t_loss=train_loss,\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(D_in, H)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        a1 = self.fc1(input_.float())\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = SimpleNet().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/015] train_loss: 13.8268     val_loss 13.8135 train_acc 0.4997 val_acc 0.5001\n",
      "\n",
      "[002/015] train_loss: 13.8136     val_loss 13.8135 train_acc 0.5001 val_acc 0.5001\n",
      "\n",
      "[003/015] train_loss: 13.8142     val_loss 13.8135 train_acc 0.5001 val_acc 0.5001\n",
      "\n",
      "[004/015] train_loss: 13.8149     val_loss 13.8135 train_acc 0.5000 val_acc 0.5001\n",
      "\n",
      "[005/015] train_loss: 13.8149     val_loss 13.8135 train_acc 0.5000 val_acc 0.5001\n",
      "\n",
      "[006/015] train_loss: 13.8162     val_loss 13.8135 train_acc 0.5000 val_acc 0.5001\n",
      "\n",
      "[007/015] train_loss: 13.8116     val_loss 13.8135 train_acc 0.5002 val_acc 0.5001\n",
      "\n",
      "[008/015] train_loss: 13.8129     val_loss 13.8135 train_acc 0.5001 val_acc 0.5001\n",
      "\n",
      "[009/015] train_loss: 13.8136     val_loss 13.8135 train_acc 0.5001 val_acc 0.5001\n",
      "\n",
      "[010/015] train_loss: 13.8142     val_loss 13.8135 train_acc 0.5001 val_acc 0.5001\n",
      "\n",
      "[011/015] train_loss: 13.8136     val_loss 13.8135 train_acc 0.5001 val_acc 0.5001\n",
      "\n",
      "[012/015] train_loss: 13.8176     val_loss 13.8135 train_acc 0.4999 val_acc 0.5001\n",
      "\n",
      "[013/015] train_loss: 13.8149     val_loss 13.8135 train_acc 0.5000 val_acc 0.5001\n",
      "\n",
      "[014/015] train_loss: 13.8149     val_loss 13.8135 train_acc 0.5000 val_acc 0.5001\n",
      "\n",
      "[015/015] train_loss: 13.8116     val_loss 13.8135 train_acc 0.5002 val_acc 0.5001\n"
     ]
    }
   ],
   "source": [
    "simple_history = train(X_train, y_train, X_test, y_test, simple_model, \n",
    "      epochs=15, verbose=1, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion : Why was the performance bad ? What was wrong with tokenization ? \n",
    "\n",
    "### MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS\n",
    "\n",
    "#### What is an embedding layer ? \n",
    "\n",
    "An embedding is a linear projection from one vector space to another. We usually use embeddings to project the one-hot encodings of words on to a lower-dimensional continuous space so that the input surface is dense and possibly smooth. According to the model, an embedding layer is just a transformation from $\\mathbb{R}^{inp}$ to $\\mathbb{R}^{emb}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do embedding to dim 100 (in keras, tf, PyTorch: with Embedding layer) and after flattening add a dense layer with 250 units. Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_emb = 100\n",
    "class EmbeddingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocabulary_size, H_emb)\n",
    "        self.fc1 = nn.Linear(H_emb * D_in, H)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        emb = self.emb(input_.long()).view((input_.size(0), -1))\n",
    "        a1 = self.fc1(emb)\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/050] train_loss: 0.7319     val_loss 0.6948 train_acc 0.5175 val_acc 0.5338\n",
      "\n",
      "[006/050] train_loss: 0.5929     val_loss 0.6779 train_acc 0.6938 val_acc 0.5775\n",
      "\n",
      "[011/050] train_loss: 0.5442     val_loss 0.6948 train_acc 0.7397 val_acc 0.5872\n",
      "\n",
      "[016/050] train_loss: 0.4990     val_loss 0.7773 train_acc 0.7608 val_acc 0.5694\n",
      "\n",
      "[021/050] train_loss: 0.4665     val_loss 0.7867 train_acc 0.7791 val_acc 0.5772\n",
      "\n",
      "[026/050] train_loss: 0.4318     val_loss 0.6927 train_acc 0.8031 val_acc 0.6246\n",
      "\n",
      "[031/050] train_loss: 0.4083     val_loss 0.8338 train_acc 0.8159 val_acc 0.5904\n",
      "\n",
      "[036/050] train_loss: 0.3709     val_loss 0.7963 train_acc 0.8377 val_acc 0.6089\n",
      "\n",
      "[041/050] train_loss: 0.3792     val_loss 0.8515 train_acc 0.8357 val_acc 0.6051\n",
      "\n",
      "[046/050] train_loss: 0.3307     val_loss 0.7944 train_acc 0.8556 val_acc 0.6233\n",
      "\n",
      "[050/050] train_loss: 0.3399     val_loss 0.8259 train_acc 0.8534 val_acc 0.6208\n"
     ]
    }
   ],
   "source": [
    "emb_model = EmbeddingNet().to(DEVICE)\n",
    "emb_history = train(X_train, y_train, X_test, y_test, emb_model, \n",
    "      epochs=50, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2 : CONVOLUTIONAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog.\n",
    "\n",
    "http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/\n",
    "\n",
    "Fit a 1D convolution with 200 filters, kernel size 3 followed by a feedforward layer of 250 nodes and ReLU, sigmoid activations as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_conv = 100\n",
    "k_size = 3\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv =nn.Conv1d(D_in, H_conv,kernel_size=k_size, padding=k_size//2)\n",
    "        self.fc1 = nn.Linear(D_in, 1)\n",
    "        self.out = nn.ReLU()\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        conv = self.conv(input_.unsqueeze(1))\n",
    "        a1 = self.fc1(conv)\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 100 500 3, expected input[64, 1, 500] to have 500 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-62b8f974151c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconv_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m conv_history = train(X_train, y_train, X_test, y_test, conv_model, \n\u001b[0;32m----> 3\u001b[0;31m       epochs=50, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-de9bc5ac7d9e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, y, X_val, y_val, model, epochs, verbose, learning_rate, criteria, optimizer, batch_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-de9bc5ac7d9e>\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(inputs, labels, model, criteria, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-644d548f5008>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 100 500 3, expected input[64, 1, 500] to have 500 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "conv_model = ConvNet().to(DEVICE)\n",
    "conv_history = train(X_train, y_train, X_test, y_test, conv_model, \n",
    "      epochs=50, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 3 : SIMPLE RNN\n",
    "\n",
    "Two of the best blogs that help understand the workings of a RNN and LSTM are\n",
    "\n",
    "1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "2. http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "Mathematically speaking, a simple RNN does the following. It constructs a set of hidden states using the state variable from the previous timestep and the input at current time. Mathematically, a simpleRNN can be defined by the following relation.\n",
    "\n",
    "<center>$h_t = \\sigma(W([h_{t-1},x_{t}])+b)$\n",
    "    \n",
    "If we extend this recurrence relation to the length of sequences we have in hand, we have our RNN network constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do simple RNN (keras, rf: SimpleRNN layer, pytorch: RNN layer) with 100 units with the input from embedding layer. How are the results different from the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_emb = 100\n",
    "class RNNNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocabulary_size, H_emb)\n",
    "        self.rnn = nn.RNN(H_emb, H)\n",
    "        self.fc1 = nn.Linear(D_in * H, H)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        emb = self.emb(input_.long())\n",
    "        a1, hid = self.rnn(emb)\n",
    "        a1 = self.fc1(a1.view((input_.size(0), -1)))\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/050] train_loss: 0.6949     val_loss 0.6909 train_acc 0.5183 val_acc 0.5260\n",
      "\n",
      "[006/050] train_loss: 0.6381     val_loss 0.6754 train_acc 0.6733 val_acc 0.5671\n",
      "\n",
      "[011/050] train_loss: 0.5734     val_loss 0.6589 train_acc 0.7353 val_acc 0.5997\n",
      "\n",
      "[016/050] train_loss: 0.5047     val_loss 0.6651 train_acc 0.7801 val_acc 0.6021\n",
      "\n",
      "[021/050] train_loss: 0.4385     val_loss 0.6833 train_acc 0.8209 val_acc 0.6147\n",
      "\n",
      "[026/050] train_loss: 0.3891     val_loss 0.6805 train_acc 0.8425 val_acc 0.6250\n",
      "\n",
      "[031/050] train_loss: 0.3447     val_loss 0.6966 train_acc 0.8673 val_acc 0.6312\n",
      "\n",
      "[036/050] train_loss: 0.3069     val_loss 0.7295 train_acc 0.8843 val_acc 0.6281\n",
      "\n",
      "[041/050] train_loss: 0.2797     val_loss 0.8041 train_acc 0.8975 val_acc 0.6201\n",
      "\n",
      "[046/050] train_loss: 0.2522     val_loss 0.8096 train_acc 0.9102 val_acc 0.6245\n",
      "\n",
      "[050/050] train_loss: 0.2318     val_loss 0.8449 train_acc 0.9210 val_acc 0.6222\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNNet().to(DEVICE)\n",
    "rnn_history = train(X_train, y_train, X_test, y_test, rnn_model,\n",
    "      epochs=50, verbose=5, learning_rate=1e-3, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNNs and vanishing/exploding gradients\n",
    "\n",
    "Let us use sigmoid activations as example. Derivative of a sigmoid can be written as \n",
    "<center> $\\sigma'(x) = \\sigma(x) \\cdot \\sigma(1-x)$. </center>\n",
    "\n",
    "<img src = \"fig/vanishing_gradients.png\">\n",
    "Remember RNN is a \"really deep\" feedforward network (when unrolled in time). Hence, backpropagation happens from $h_t$ all the way to $h_1$. Also realize that sigmoid gradients are multiplicatively dependent on the value of sigmoid. Hence, if the non-activated output of any layer $h_l$ is < 0, then $\\sigma$ tends to 0, effectively \"vanishing\" gradient. Any layer that the current layer backprops to $H_{1:L-1}$ do not learn anything useful out of the gradients.\n",
    "\n",
    "#### LSTMs and GRU\n",
    "LSTM and GRU are two sophisticated implementations of RNN which essentially are built on what we call as gates. A gate is a probability number between 0 and 1. For instance, LSTM is built on these state updates \n",
    "\n",
    "Note : L is just a linear transformation L(x) = W*x + b.\n",
    "\n",
    "$f_t = \\sigma(L([h_{t-1},x_t))$\n",
    "\n",
    "$i_t = \\sigma(L([h_{t-1},x_t))$\n",
    "\n",
    "$o_t = \\sigma(L([h_{t-1},x_t))$\n",
    "\n",
    "$\\hat{C}_t = \\tanh(L([h_{t-1},x_t))$\n",
    "\n",
    "$C_t = f_t * C_{t-1}+i_t*\\hat{C}_t$  (Using the forget gate, the neural network can learn to control how much information it has to retain or forget)\n",
    "\n",
    "$h_t = o_t * \\tanh(c_t)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 4 : LSTM\n",
    "\n",
    "In the next step, we will implement a LSTM model to do classification. Use the same architecture as before. Try experimenting with increasing the number of nodes, stacking multiple layers, applyong dropouts etc. Check the number of parameters that this model entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_emb = 100\n",
    "class LSTMNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocabulary_size, H_emb)\n",
    "        self.lstm = nn.LSTM(H_emb, H)\n",
    "        self.fc1 = nn.Linear(D_in * H, H)\n",
    "        self.out = nn.Linear(H, D_out)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        emb = self.emb(input_.long())\n",
    "        a1, hid = self.lstm(emb)\n",
    "        a1 = self.fc1(a1.view((input_.size(0), -1)))\n",
    "        a2 = self.out(a1)\n",
    "        y = self.out_act(a2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[001/050] train_loss: 0.6975     val_loss 0.6953 train_acc 0.5109 val_acc 0.5072\n",
      "\n",
      "[006/050] train_loss: 0.6479     val_loss 0.6762 train_acc 0.6543 val_acc 0.5725\n",
      "\n",
      "[011/050] train_loss: 0.5123     val_loss 0.6384 train_acc 0.7625 val_acc 0.6349\n",
      "\n",
      "[016/050] train_loss: 0.3889     val_loss 0.6679 train_acc 0.8329 val_acc 0.6505\n",
      "\n",
      "[021/050] train_loss: 0.2939     val_loss 0.7279 train_acc 0.8801 val_acc 0.6607\n",
      "\n",
      "[026/050] train_loss: 0.2176     val_loss 0.7945 train_acc 0.9179 val_acc 0.6707\n",
      "\n",
      "[031/050] train_loss: 0.1587     val_loss 0.8413 train_acc 0.9453 val_acc 0.6848\n",
      "\n",
      "[036/050] train_loss: 0.1150     val_loss 0.9272 train_acc 0.9635 val_acc 0.6881\n",
      "\n",
      "[041/050] train_loss: 0.0854     val_loss 0.9977 train_acc 0.9754 val_acc 0.6895\n",
      "\n",
      "[046/050] train_loss: 0.0624     val_loss 1.0853 train_acc 0.9839 val_acc 0.6958\n",
      "\n",
      "[050/050] train_loss: 0.0490     val_loss 1.1177 train_acc 0.9891 val_acc 0.6979\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTMNet().to(DEVICE)\n",
    "lstm_history = train(X_train, y_train, X_test, y_test, lstm_model,\n",
    "      epochs=50, verbose=5, learning_rate=1e-2, criteria=criteria, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 5 : CNN + LSTM \n",
    "\n",
    "CNNs are good at learning spatial features and sentences can be thought of as 1-D spatial vectors (dimension being connotated by the sequence ordering among the words in the sentence.). We apply a LSTM over the features learned by the CNN (after a maxpooling layer). This leverages the power of CNNs and LSTMs combined. We expect the CNN to be able to pick out invariant features across the 1-D spatial structure(i.e. sentence) that characterize good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer followed by a feedforward for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "\n",
    "We saw the power of sequence models and how they are useful in text classification. They give a solid performance, low memory footprint (thanks to shared parameters) and are able to understand and leverage the temporally connected information contained in the inputs. There is still an open debate about the performance vs memory benefits of CNNs vs RNNs in the research community."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_ukma]",
   "language": "python",
   "name": "conda-env-ml_ukma-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
