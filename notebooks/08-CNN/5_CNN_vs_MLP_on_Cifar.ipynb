{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN vs MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, \\\n",
    "GlobalAveragePooling2D, Input, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_original():\n",
    "    #READ DATA FRAME\n",
    "    (full_x_train, full_y_train), (full_x_test, full_y_test) = cifar10.load_data()\n",
    "    full_x_train = full_x_train.astype('float32')\n",
    "    \n",
    "    #z-score\n",
    "    mean = np.mean(full_x_train,axis=(0,1,2,3))\n",
    "    std = np.std(full_x_train,axis=(0,1,2,3))\n",
    "    full_x_train = (full_x_train-mean)/(std+1e-7)\n",
    "    full_x_test = (full_x_test-mean)/(std+1e-7)\n",
    "    \n",
    "    return (full_x_train, full_y_train), (full_x_test, full_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_x_train, full_y_train), (full_x_test, full_y_test) = read_data_original()\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "full_y_train = np_utils.to_categorical(full_y_train,num_classes)\n",
    "full_y_test = np_utils.to_categorical(full_y_test,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=5,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=5,\n",
    "        channel_shift_range=0.1,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen.fit(full_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /cyclope/nshvai/.nshvai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(100, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(32,32,3)))\n",
    "model.add(Conv2D(100, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(200, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(200, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "\n",
    "model.add(Conv2D(400, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(400, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(Conv2D(800, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(800, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "model.add(Dropout(0.125))\n",
    "model.add(Dense(2000))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation=\"softmax\", name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 100)       2800      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 100)       90100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 100)       400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 100)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 200)       180200    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 200)       360200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 200)       800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 400)         720400    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 400)         1440400   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 400)         1600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 400)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 400)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 800)         2880800   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 800)         5760800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 800)         3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 800)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              1602000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 13,063,710\n",
      "Trainable params: 13,060,710\n",
      "Non-trainable params: 3,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cyclope/nshvai/.nshvai/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 1.6912 - acc: 0.4160 - val_loss: 1.3533 - val_acc: 0.5121\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 58s 233ms/step - loss: 1.2180 - acc: 0.5642 - val_loss: 1.4801 - val_acc: 0.5224\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 1.0465 - acc: 0.6272 - val_loss: 0.9544 - val_acc: 0.6660\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 0.9304 - acc: 0.6718 - val_loss: 0.9007 - val_acc: 0.6871\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 0.8511 - acc: 0.7011 - val_loss: 0.8138 - val_acc: 0.7169\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 0.7880 - acc: 0.7231 - val_loss: 0.8020 - val_acc: 0.7224\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.7313 - acc: 0.7441 - val_loss: 0.8275 - val_acc: 0.7231\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.6871 - acc: 0.7577 - val_loss: 0.7335 - val_acc: 0.7550\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.6536 - acc: 0.7706 - val_loss: 0.7351 - val_acc: 0.7498\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.6173 - acc: 0.7833 - val_loss: 0.6397 - val_acc: 0.7771\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 0.5910 - acc: 0.7919 - val_loss: 0.5940 - val_acc: 0.7996\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.5600 - acc: 0.8033 - val_loss: 0.5813 - val_acc: 0.7959\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 0.5407 - acc: 0.8100 - val_loss: 0.5937 - val_acc: 0.8002\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.5185 - acc: 0.8181 - val_loss: 0.6544 - val_acc: 0.7806\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.5003 - acc: 0.8245 - val_loss: 0.5346 - val_acc: 0.8167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44d83b0c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(full_x_train, full_y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(full_x_train)//batch_size,\n",
    "                        validation_data=(full_x_test, full_y_test),\n",
    "                        epochs=epochs, verbose=1, workers=20,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 116us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(full_x_test, full_y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5345783334970474, 0.8167000019550323]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense = Sequential()\n",
    "#model_dense.add(Input(shape=(32,32,3)))\n",
    "model_dense.add(Flatten(input_shape=(32,32,3)))\n",
    "\n",
    "\n",
    "model_dense.add(Dropout(0.125))\n",
    "model_dense.add(Dense(2000))\n",
    "model_dense.add(Dropout(0.25))\n",
    "model_dense.add(Dense(10, activation=\"softmax\", name=\"predictions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2000)              6146000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                20010     \n",
      "=================================================================\n",
      "Total params: 6,166,010\n",
      "Trainable params: 6,166,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense.compile(loss='categorical_crossentropy',\n",
    "            optimizer=keras.optimizers.SGD(lr=0.001),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 63s 252ms/step - loss: 2.6071 - acc: 0.2063 - val_loss: 1.9805 - val_acc: 0.3125\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 2.4136 - acc: 0.2391 - val_loss: 1.9000 - val_acc: 0.3419\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 58s 234ms/step - loss: 2.3413 - acc: 0.2525 - val_loss: 1.8631 - val_acc: 0.3537\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 61s 242ms/step - loss: 2.3008 - acc: 0.2583 - val_loss: 1.8423 - val_acc: 0.3581\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 72s 287ms/step - loss: 2.2607 - acc: 0.2663 - val_loss: 1.8255 - val_acc: 0.3675\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 71s 283ms/step - loss: 2.2378 - acc: 0.2696 - val_loss: 1.8094 - val_acc: 0.3687\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 70s 279ms/step - loss: 2.2172 - acc: 0.2753 - val_loss: 1.8042 - val_acc: 0.3744\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 66s 262ms/step - loss: 2.1918 - acc: 0.2763 - val_loss: 1.7930 - val_acc: 0.3746\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 2.1721 - acc: 0.2759 - val_loss: 1.7894 - val_acc: 0.3756\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 61s 246ms/step - loss: 2.1554 - acc: 0.2817 - val_loss: 1.7812 - val_acc: 0.3846\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 2.1428 - acc: 0.2839 - val_loss: 1.7762 - val_acc: 0.3840\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 2.1350 - acc: 0.2833 - val_loss: 1.7716 - val_acc: 0.3841\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 2.1193 - acc: 0.2871 - val_loss: 1.7698 - val_acc: 0.3870\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 2.1125 - acc: 0.2881 - val_loss: 1.7634 - val_acc: 0.3897\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 61s 244ms/step - loss: 2.0998 - acc: 0.2900 - val_loss: 1.7596 - val_acc: 0.3920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44585bd5c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dense.fit_generator(datagen.flow(full_x_train, full_y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(full_x_train)//batch_size,\n",
    "                        validation_data=(full_x_test, full_y_test),\n",
    "                        epochs=epochs, verbose=1, workers=20,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 49us/step\n"
     ]
    }
   ],
   "source": [
    "scores_dense = model_dense.evaluate(full_x_test, full_y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.75955637216568, 0.39199999868869784]\n"
     ]
    }
   ],
   "source": [
    "print(scores_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For images and video processing, advantages of CNN over MLP constitute in:\n",
    "- ability to extract spacial features (in a \"natural\" way, with a sliding window)\n",
    "- shift robustness\n",
    "- lower complexity (for larger images)\n",
    "- tranferrability to different image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nshvai",
   "language": "python",
   "name": ".nshvai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
