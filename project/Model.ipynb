{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH = 'data/input'\n",
    "zip_file = 'spooky-author-identification.zip'\n",
    "os.listdir(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'sample_submission.zip',\n",
       " 'test.csv',\n",
       " 'test.zip',\n",
       " 'train.csv',\n",
       " 'train.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(INPUT_PATH):\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(f'{INPUT_PATH}/{filename}', 'r') as zip_ref:\n",
    "            zip_ref.extractall(INPUT_PATH)\n",
    "            os.remove(f'{INPUT_PATH}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{INPUT_PATH}/train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "df['processed'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count chars and words\n",
    "df['n_chars'] = df['processed'].apply(lambda x: len(x))\n",
    "df['n_words'] = df['processed'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count punctuation marks\n",
    "df['n_punctuation'] = df['processed'].apply(lambda x: len([dig for dig in list(x) if dig in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation marks\n",
    "df['processed'] = df['processed'].apply(lambda x: ''.join(ch for ch in x if ch not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_punctuation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>231</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>200</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>206</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>174</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  n_chars  n_words  \\\n",
       "id                                                                             \n",
       "id26305  this process however afforded me no means of a...      231       41   \n",
       "id17569  it never once occurred to me that the fumbling...       71       14   \n",
       "id11008  in his left hand was a gold snuff box from whi...      200       36   \n",
       "id27763  how lovely is spring as we looked from windsor...      206       34   \n",
       "id12958  finding nothing else not even gold the superin...      174       27   \n",
       "\n",
       "         n_punctuation  \n",
       "id                      \n",
       "id26305              7  \n",
       "id17569              1  \n",
       "id11008              5  \n",
       "id27763              4  \n",
       "id12958              4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count nouns, adjetives and verbs\n",
    "nouns = ('NN','NNP','NNPS','NNS')\n",
    "adjectives = ('JJ','JJR','JJS')\n",
    "verbs = ('VB','VBD','VBG','VBN','VBP','VBZ')\n",
    "\n",
    "df['n_noun'] = df['processed'].apply(lambda x: sum(np.in1d(np.array(pos_tag(word_tokenize(x)))[:,1], nouns)))\n",
    "df['n_adj'] = df['processed'].apply(lambda x: sum(np.in1d(np.array(pos_tag(word_tokenize(x)))[:,1], adjectives)))\n",
    "df['n_verb'] = df['processed'].apply(lambda x: sum(np.in1d(np.array(pos_tag(word_tokenize(x)))[:,1], verbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count stopwords\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "df['n_stopwords'] = df['processed'].apply(lambda x: sum(np.in1d(word_tokenize(x), eng_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique words\n",
    "df['n_unique'] = df['processed'].apply(lambda x: len(set(word_tokenize(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fractions\n",
    "\n",
    "for count in ['n_noun', 'n_adj', 'n_verb', 'n_stopwords', 'n_unique']:\n",
    "    df['fract'+count[1:]] = df[count] / df['n_words']\n",
    "    \n",
    "df['fract_punctuation'] = df['n_punctuation']/df['n_chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>processed</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_punctuation</th>\n",
       "      <th>n_noun</th>\n",
       "      <th>n_adj</th>\n",
       "      <th>n_verb</th>\n",
       "      <th>n_stopwords</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>fract_noun</th>\n",
       "      <th>fract_adj</th>\n",
       "      <th>fract_verb</th>\n",
       "      <th>fract_stopwords</th>\n",
       "      <th>fract_unique</th>\n",
       "      <th>fract_punctuation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>this process however afforded me no means of a...</td>\n",
       "      <td>231</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>it never once occurred to me that the fumbling...</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>in his left hand was a gold snuff box from whi...</td>\n",
       "      <td>200</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>how lovely is spring as we looked from windsor...</td>\n",
       "      <td>206</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.019417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>finding nothing else not even gold the superin...</td>\n",
       "      <td>174</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.022989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...    EAP   \n",
       "id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 processed  n_chars  n_words  \\\n",
       "id                                                                             \n",
       "id26305  this process however afforded me no means of a...      231       41   \n",
       "id17569  it never once occurred to me that the fumbling...       71       14   \n",
       "id11008  in his left hand was a gold snuff box from whi...      200       36   \n",
       "id27763  how lovely is spring as we looked from windsor...      206       34   \n",
       "id12958  finding nothing else not even gold the superin...      174       27   \n",
       "\n",
       "         n_punctuation  n_noun  n_adj  n_verb  n_stopwords  n_unique  \\\n",
       "id                                                                     \n",
       "id26305              7      12      2       6            0        35   \n",
       "id17569              1       2      1       2            0        14   \n",
       "id11008              5      10      5       4            0        32   \n",
       "id27763              4      10      6       5            0        31   \n",
       "id12958              4       6      1       6            0        25   \n",
       "\n",
       "         fract_noun  fract_adj  fract_verb  fract_stopwords  fract_unique  \\\n",
       "id                                                                          \n",
       "id26305    0.292683   0.048780    0.146341              0.0      0.853659   \n",
       "id17569    0.142857   0.071429    0.142857              0.0      1.000000   \n",
       "id11008    0.277778   0.138889    0.111111              0.0      0.888889   \n",
       "id27763    0.294118   0.176471    0.147059              0.0      0.911765   \n",
       "id12958    0.222222   0.037037    0.222222              0.0      0.925926   \n",
       "\n",
       "         fract_punctuation  \n",
       "id                          \n",
       "id26305           0.030303  \n",
       "id17569           0.014085  \n",
       "id11008           0.025000  \n",
       "id27763           0.019417  \n",
       "id12958           0.022989  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.98 s, sys: 3.47 ms, total: 5.99 s\n",
      "Wall time: 5.98 s\n"
     ]
    }
   ],
   "source": [
    "stemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "def stem(s):\n",
    "    return ' '.join([stemmer.stem(word) for word in word_tokenize(s)])\n",
    "\n",
    "%time df['processed'] = df['processed'].apply(lambda x: stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = list(df.columns[df.columns.get_loc('processed'):])\n",
    "X, y = df[train_cols].copy(), df['author'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pipe = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer(stop_words=eng_stopwords)),\n",
    "# #     ('decompose', TSNE(n_components=2, random_state=42, verbose=False)),\n",
    "# ])\n",
    "\n",
    "# %time X = np.concatenate([X, text_pipe.fit_transform(X['processed'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # text_pipe = TfidfVectorizer(stop_words=eng_stopwords)\n",
    "# %time text_pipe.fit(X_train['processed'])\n",
    "# %time X_train = np.concatenate([X_train, text_pipe.transform(X_train['processed'])], axis=1)\n",
    "# %time X_test = np.concatenate([X_test, text_pipe.transform(X_test['processed'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=eng_stopwords, min_df=3)\n",
    "tfidf.fit(X_train['processed'])\n",
    "X_train = np.concatenate([X_train, tfidf.transform(X_train['processed']).toarray()], axis=1)\n",
    "X_test = np.concatenate([X_test, tfidf.transform(X_test['processed']).toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13117, 6805)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train[:, 1:], X_test[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ........................ alpha=0.001, score=-0.519, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ........................ alpha=0.001, score=-0.511, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ........................ alpha=0.001, score=-0.499, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.7s remaining:    0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ........................ alpha=0.001, score=-0.519, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.6s remaining:    0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ......................... alpha=0.01, score=-0.468, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.5s remaining:    0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ......................... alpha=0.01, score=-0.465, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.4s remaining:    0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ......................... alpha=0.01, score=-0.453, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.3s remaining:    0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ......................... alpha=0.01, score=-0.462, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   15.1s remaining:    0.0s\n",
      "[CV] alpha=0.05 ......................................................\n",
      "[CV] ......................... alpha=0.05, score=-0.463, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.0s remaining:    0.0s\n",
      "[CV] alpha=0.05 ......................................................\n",
      "[CV] ......................... alpha=0.05, score=-0.463, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.8s remaining:    0.0s\n",
      "[CV] alpha=0.05 ......................................................\n",
      "[CV] ......................... alpha=0.05, score=-0.451, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   20.7s remaining:    0.0s\n",
      "[CV] alpha=0.05 ......................................................\n",
      "[CV] ......................... alpha=0.05, score=-0.453, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   22.5s remaining:    0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] .......................... alpha=0.1, score=-0.474, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   24.4s remaining:    0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] .......................... alpha=0.1, score=-0.475, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   26.2s remaining:    0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] .......................... alpha=0.1, score=-0.463, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   28.1s remaining:    0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] .......................... alpha=0.1, score=-0.463, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   30.0s remaining:    0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .......................... alpha=0.5, score=-0.545, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   31.8s remaining:    0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .......................... alpha=0.5, score=-0.550, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   33.7s remaining:    0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .......................... alpha=0.5, score=-0.541, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   35.5s remaining:    0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .......................... alpha=0.5, score=-0.536, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   37.4s remaining:    0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ............................ alpha=1, score=-0.605, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   39.2s remaining:    0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ............................ alpha=1, score=-0.614, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   41.1s remaining:    0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ............................ alpha=1, score=-0.605, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   42.9s remaining:    0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ............................ alpha=1, score=-0.600, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   44.8s remaining:    0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "[CV] ........................... alpha=10, score=-2.160, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   46.7s remaining:    0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "[CV] ........................... alpha=10, score=-2.247, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   48.5s remaining:    0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "[CV] ........................... alpha=10, score=-2.250, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   50.3s remaining:    0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "[CV] ........................... alpha=10, score=-2.319, total=   1.6s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   52.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   52.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=MultinomialNB(), n_jobs=1,\n",
       "             param_grid={'alpha': (0.001, 0.01, 0.05, 0.1, 0.5, 1, 10)},\n",
       "             scoring='neg_log_loss', verbose=100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(\n",
    "    MultinomialNB(),\n",
    "    param_grid = { 'alpha':(0.001, 0.01,0.05, 0.1, 0.5, 1, 10)},\n",
    "    scoring='neg_log_loss',\n",
    "    n_jobs = 1,\n",
    "    cv=4,\n",
    "    verbose=100,\n",
    "    refit=True\n",
    ")\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.05)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = gs.best_estimator_\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200247601361808"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_params = {\n",
    "#     'max_depth': [i for i in range(20, 1000)],\n",
    "#     'min_samples_split': [i for i in range(2, 20)],\n",
    "#     'min_samples_leaf': [i for i in range(1, 20)],\n",
    "#     'max_features': uniform(loc=0.01, scale =0.4),\n",
    "#     'max_samples': uniform(loc=0.2, scale =0.8)\n",
    "# #     'max_leaf_nodes': [i for i in range(2, 100)],\n",
    "# }\n",
    "\n",
    "# rs = RandomizedSearchCV(\n",
    "#     RandomForestClassifier(n_estimators = 5, random_state=42, n_jobs=-1),\n",
    "#     search_params,\n",
    "#     n_iter=30,\n",
    "#     scoring='neg_log_loss',\n",
    "#     n_jobs = 1,\n",
    "#     cv=3,\n",
    "#     verbose=100,\n",
    "#     refit=False,\n",
    "#     random_state=42\n",
    "# )\n",
    "# rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=710, max_features=0.0225716742746937,\n",
       "                       max_samples=0.7091283290110244, min_samples_leaf=4,\n",
       "                       min_samples_split=6, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = dict(max_depth=710, max_features=0.0225716742746937,\n",
    "                       max_samples=0.7091283290110244, min_samples_leaf=4,\n",
    "                       min_samples_split=6)\n",
    "rf_params['n_estimators'] = 200\n",
    "rf_params['random_state'] = 42\n",
    "rf_params['n_jobs'] = -1\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6487155679356237"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 39s, sys: 766 ms, total: 7min 40s\n",
      "Wall time: 7min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daryna/anaconda3/envs/ml_ukma/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=1200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('svm', SVC(max_iter=1200, random_state=42))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipe= Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('svm', SVC(max_iter=1200, random_state=42))\n",
    "])\n",
    "\n",
    "%time svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7595171773444754"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, svm_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('nb', MultinomialNB(alpha=0.05)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(max_depth=710,\n",
       "                                                     max_features=0.0225716742746937,\n",
       "                                                     max_samples=0.7091283290110244,\n",
       "                                                     min_samples_leaf=4,\n",
       "                                                     min_samples_split=6,\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=42)),\n",
       "                             ('svm',\n",
       "                              Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                              ('svm',\n",
       "                                               SVC(max_iter=1200,\n",
       "                                                   random_state=42))]))],\n",
       "                 n_jobs=-1, verbose=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf = VotingClassifier(\n",
    "    estimators = [('nb', nb), ('rf', rf), ('svm', svm_pipe)],\n",
    "#     final_estimator=LogisticRegression(),\n",
    "    n_jobs=-1,\n",
    "#     cv=3,\n",
    "    verbose=10\n",
    ")\n",
    "vote_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80099040544723"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, vote_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MultinomialNB(alpha=0.05),\n",
       " RandomForestClassifier(max_depth=710, max_features=0.0225716742746937,\n",
       "                        max_samples=0.7091283290110244, min_samples_leaf=4,\n",
       "                        min_samples_split=6, n_estimators=200, n_jobs=-1,\n",
       "                        random_state=42),\n",
       " Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                 ('svm', SVC(max_iter=1200, random_state=42))])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 0.8200247601361808\n",
      "RandomForestClassifier 0.6487155679356237\n",
      "Pipeline 0.7595171773444754\n",
      "VotingClassifier 0.80099040544723\n"
     ]
    }
   ],
   "source": [
    "for clf in [nb, rf, svm_pipe, vote_clf]:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 17)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_ukma]",
   "language": "python",
   "name": "conda-env-ml_ukma-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
